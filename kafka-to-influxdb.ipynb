{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "757a9a6d-1806-4de6-9492-752822ee9185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kafka-python in /opt/app-root/lib/python3.9/site-packages (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "380121b3-742a-4a31-83c8-3f1d5f0605dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/app-root/lib/python3.9/site-packages (4.30.2)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.9/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/app-root/lib/python3.9/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/app-root/lib/python3.9/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib/python3.9/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/app-root/lib/python3.9/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/app-root/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/app-root/lib/python3.9/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/app-root/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/app-root/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers) (2023.5.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbb70a42-3891-4759-809e-325e3d6f6b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/app-root/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.9/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/app-root/lib/python3.9/site-packages (from torch) (4.6.3)\n",
      "Requirement already satisfied: sympy in /opt/app-root/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib/python3.9/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/app-root/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/app-root/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/app-root/lib/python3.9/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/app-root/lib/python3.9/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/app-root/lib/python3.9/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/app-root/lib/python3.9/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/app-root/lib/python3.9/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/app-root/lib/python3.9/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/app-root/lib/python3.9/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/app-root/lib/python3.9/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/app-root/lib/python3.9/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/app-root/lib/python3.9/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /opt/app-root/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (67.8.0)\n",
      "Requirement already satisfied: wheel in /opt/app-root/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: cmake in /opt/app-root/lib/python3.9/site-packages (from triton==2.0.0->torch) (3.26.4)\n",
      "Requirement already satisfied: lit in /opt/app-root/lib/python3.9/site-packages (from triton==2.0.0->torch) (16.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/app-root/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bf637ce-0895-403f-8d42-a92b6b82ddb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cloudevents in /opt/app-root/lib/python3.9/site-packages (1.9.0)\n",
      "Requirement already satisfied: deprecation<3.0,>=2.0 in /opt/app-root/lib/python3.9/site-packages (from cloudevents) (2.1.0)\n",
      "Requirement already satisfied: packaging in /opt/app-root/lib/python3.9/site-packages (from deprecation<3.0,>=2.0->cloudevents) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/app-root/lib/python3.9/site-packages (from packaging->deprecation<3.0,>=2.0->cloudevents) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cloudevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c30dd3d6-4358-4641-bcac-086476937821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: influxdb in /opt/app-root/lib/python3.9/site-packages (5.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.0 in /opt/app-root/lib/python3.9/site-packages (from influxdb) (2.8.2)\n",
      "Requirement already satisfied: pytz in /opt/app-root/lib/python3.9/site-packages (from influxdb) (2023.3)\n",
      "Requirement already satisfied: requests>=2.17.0 in /opt/app-root/lib/python3.9/site-packages (from influxdb) (2.31.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/app-root/lib/python3.9/site-packages (from influxdb) (1.16.0)\n",
      "Requirement already satisfied: msgpack in /opt/app-root/lib/python3.9/site-packages (from influxdb) (1.0.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib/python3.9/site-packages (from requests>=2.17.0->influxdb) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests>=2.17.0->influxdb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib/python3.9/site-packages (from requests>=2.17.0->influxdb) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests>=2.17.0->influxdb) (2023.5.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install influxdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "916a2294-14a5-4a0b-8bf5-032107c5a135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: influxdb-client in /opt/app-root/lib/python3.9/site-packages (1.36.1)\n",
      "Requirement already satisfied: reactivex>=4.0.4 in /opt/app-root/lib/python3.9/site-packages (from influxdb-client) (4.0.4)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /opt/app-root/lib/python3.9/site-packages (from influxdb-client) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/app-root/lib/python3.9/site-packages (from influxdb-client) (2.8.2)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/app-root/lib/python3.9/site-packages (from influxdb-client) (67.8.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/app-root/lib/python3.9/site-packages (from influxdb-client) (1.26.16)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.9/site-packages (from python-dateutil>=2.5.3->influxdb-client) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.1 in /opt/app-root/lib/python3.9/site-packages (from reactivex>=4.0.4->influxdb-client) (4.6.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install influxdb-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5597f6cd-f796-461d-9506-8b7609e72554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program to copy data from kafka producer and move to influxdb database.\n",
    "# Following is the data being processed\n",
    "'''\n",
    "{\n",
    "    \"specversion\": \"1.0\",\n",
    "    \"type\": \"reviews\",\n",
    "    \"source\": \"reviews-generators\",\n",
    "    \"id\": \"e5443902-ff87-414b-8ec8-92da00e641c5\",\n",
    "    \"time\": \"2023-06-15T19:36:24.895029Z\",\n",
    "    \"subject\": \"product-reviews\",\n",
    "    \"data\": {\n",
    "        \"product\": {\n",
    "            \"product_id\": \"829300\",\n",
    "            \"product_name\": \"Quarkus T-shirt\",\n",
    "            \"category\": \"clothing\"\n",
    "        },\n",
    "        \"user\": {\n",
    "            \"name\": \"Alison Silva\",\n",
    "            \"customer_id\": \"asilva\",\n",
    "            \"browser\": \"Chrome\",\n",
    "            \"region\": \"India\"\n",
    "        },\n",
    "        \"rating\": 0,\n",
    "        \"timestamp\": \"1686568446615\",\n",
    "        \"review_text\": \"This is good way to go to market\",\n",
    "        \"score\": -1,\n",
    "        \"response\": \"Non-Abusive\"\n",
    "    }\n",
    "}\n",
    "'''\n",
    "\n",
    "from kafka.consumer import KafkaConsumer\n",
    "from kafka.producer import KafkaProducer\n",
    "from kafka.errors import KafkaError\n",
    "from transformers import pipeline\n",
    "import ssl\n",
    "import json\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from ssl import SSLContext, PROTOCOL_TLSv1\n",
    "from influxdb import InfluxDBClient\n",
    "import influxdb_client\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "from influxdb_client import InfluxDBClient, Point, WriteOptions\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1b84bc2-c2ba-436b-b790-3696bae9a19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"globex-bucket\"\n",
    "org = \"globex\"\n",
    "token = \"2avH4WIAuQagJ_E5Q-SgA50x1K79IT5ruql27hH0bklvYZrrnKeuc3lvlvMx_SSvPwTlVe3chV66IcOUl43EaA==\"\n",
    "# Store the URL of your InfluxDB instance\n",
    "url=\"http://influxdb-influxdb.apps.cluster-kcmwd.kcmwd.sandbox1886.opentlc.com\"\n",
    "\n",
    "client = influxdb_client.InfluxDBClient(\n",
    "   url=url,\n",
    "   token=token,\n",
    "   org=org\n",
    ")\n",
    "\n",
    "#TRANSFORMERS_CACHE = os.environ['TRANSFORMERS_CACHE']\n",
    "#bootstrap_servers = os.environ['bootstrap_servers']\n",
    "#topic = os.environ['topic']\n",
    "#produce_topic = os.environ['produce_topic']\n",
    "#username = os.environ['username']\n",
    "#password = os.environ['password']\n",
    "#sasl_mechanism = os.environ['sasl_mechanism']\n",
    "#security_protocol = os.environ['security_protocol']\n",
    "\n",
    "#def analyze_sentiment(text):\n",
    "#    classifier = pipeline(\"sentiment-analysis\")\n",
    "#    result = classifier(text)[0]\n",
    "#    return result[\"label\"]\n",
    "\n",
    "\n",
    "#bootstrap_servers = ['af421721f4e394a0f85fcab354ff51f0-468260975.us-east-2.elb.amazonaws.com:9092']\n",
    "topic = 'reviews.moderated'\n",
    "produce_topic = 'reviews.moderated'\n",
    "bootstrap_servers = ['kafka-kafka-brokers.globex-mw-user1.svc.cluster.local:9092']\n",
    "username = 'globex'\n",
    "password = 'globex'\n",
    "sasl_mechanism = 'SCRAM-SHA-512'\n",
    "security_protocol = 'SASL_PLAINTEXT'\n",
    "\n",
    "#consumer = KafkaConsumer(\n",
    "#    produce_topic,\n",
    "#    bootstrap_servers=bootstrap_servers,\n",
    "#    auto_offset_reset='earliest',\n",
    "#    enable_auto_commit=True,\n",
    "#    value_deserializer=lambda m: json.loads(m.decode('utf-8'))\n",
    "#)\n",
    "\n",
    "# Set up a Kafka consumer\n",
    "consumer = KafkaConsumer(\n",
    "    topic,\n",
    "    bootstrap_servers=bootstrap_servers,\n",
    "    sasl_plain_username=username,\n",
    "    sasl_plain_password=password,\n",
    "    security_protocol=security_protocol,\n",
    "    sasl_mechanism=sasl_mechanism,\n",
    "    auto_offset_reset='latest',\n",
    "    enable_auto_commit=True,\n",
    "#    value_deserializer=lambda m: json.loads(m.decode('utf-8'))\n",
    ")\n",
    "\n",
    "#producer = KafkaProducer(\n",
    "#    bootstrap_servers=bootstrap_servers,\n",
    "#    value_serializer=lambda m: json.dumps(m).encode('utf-8')\n",
    "#)\n",
    "\n",
    "#influxdb_host = 'localhost'\n",
    "#influxdb_port = 8086\n",
    "#influxdb_dbname = 'globex'\n",
    "influxdb_measurement = 'sentiment-measurement'\n",
    "#influxdb_username = 'globex'\n",
    "#influxdb_password = 'globex-password'\n",
    "#influxdb_client = InfluxDBClient(influxdb_host, influxdb_port, influxdb_username, influxdb_password)\n",
    "#influxdb_client.switch_database(influxdb_dbname)\n",
    "\n",
    "# Set up a Kafka producer\n",
    "#producer = KafkaProducer(\n",
    "#    bootstrap_servers=bootstrap_servers,\n",
    "#    sasl_plain_username=username,\n",
    "#    sasl_plain_password=password,\n",
    "#    security_protocol=security_protocol,\n",
    "#    sasl_mechanism=sasl_mechanism,\n",
    "#    value_serializer=lambda m: json.dumps(m).encode('utf-8')\n",
    "#)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e572f83-8ccc-43d7-abe7-d017ce91d48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n"
     ]
    }
   ],
   "source": [
    "print(\"Test\")\n",
    "# Start consuming Kafka messages\n",
    "for message in consumer:\n",
    "    try:\n",
    "        # Get the text message from the Kafka message\n",
    "        #print(message)\n",
    "        json_payload = message.value\n",
    "        # Parse the CloudEvent from the JSON payload\n",
    "        json_data = json.loads(json_payload)\n",
    "        '''\n",
    "        json_body = [\n",
    "            {\n",
    "                \"measurement\": influxdb_measurement,\n",
    "                \"time\": json_data['time'],\n",
    "                \"fields\": {\n",
    "                    \"rating\": json_data['data']['rating'],\n",
    "                    \"timestamp\": json_data['data']['timestamp'],\n",
    "                    \"score\": json_data['data']['score']\n",
    "                },\n",
    "                \"tags\": {\n",
    "                    \"product_id\": json_data['data']['product']['product_id'],\n",
    "                    \"product_name\": json_data['data']['product']['product_name'],\n",
    "                    \"category\": json_data['data']['product']['category'],\n",
    "                    \"name\": json_data['data']['user']['name'],\n",
    "                    \"customer_id\": json_data['data']['user']['customer_id'],\n",
    "                    \"browser\": json_data['data']['user']['browser'],\n",
    "                    \"region\": json_data['data']['user']['region'],\n",
    "                    \"response\": json_data['data']['response']\n",
    "                }\n",
    "            }\n",
    "        ]'''\n",
    "        #print(json_data)\n",
    "        #json_data_data = json_data[\"data\"]\n",
    "        #print(\"DATA SPECIFIC INFORMATION\")\n",
    "        #print(json_data_data)\n",
    "        #point = influxdb_client.Point(json_data_data)\n",
    "        #print(\"POINT DATA with JSON ONLY DATA\")\n",
    "        #print(point)\n",
    "        #point = Point(\"{bucket}\")\n",
    "        #print(point)\n",
    "        #point.tag(\"data\", json_data_data[\"data\"])\n",
    "        #print(\"POINT TAG\")\n",
    "        #print(point.tag)\n",
    "        #point.time(parser.parse(json_data[\"time\"]))\n",
    "        #print(json_data)\n",
    "\n",
    "        # Create a new InfluxDB data point\n",
    "        point = influxdb_client.Point(bucket)\n",
    "        \n",
    "        #datetime_data = int(json_data_data[\"timestamp\"])\n",
    "        #print(datetime_data)\n",
    "\n",
    "        # Set the time for the data point\n",
    "        timestamp = json_data[\"timestamp\"]\n",
    "        #print(timestamp)\n",
    "        if isinstance(timestamp, str):\n",
    "            timestamp = float(timestamp)\n",
    "\n",
    "        datetime = datetime.fromtimestamp(timestamp/1000.0)\n",
    "        #print(datetime)\n",
    "        #datetime = datetime.strptime(datetime, '%m/%d/%Y, %H:%M:%S')\n",
    "        datetime_str = datetime.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "        #print(datetime_str)\n",
    "\n",
    "        point.time(parser.parse(datetime_str))\n",
    "\n",
    "        # Flatten the \"product\" field\n",
    "        product = json_data[\"product\"]\n",
    "        #print(\"Print product information before for loop to flatten it\")\n",
    "        #print(product)\n",
    "\n",
    "        # Set the \"product\" fields\n",
    "        for key, value in json_data[\"product\"].items():\n",
    "            if key != \"product\":\n",
    "                if isinstance(value, dict):\n",
    "                    # Handle other nested fields if needed\n",
    "                    pass\n",
    "                else:\n",
    "                    point.field(key, value)\n",
    "\n",
    "            with InfluxDBClient(url, token) as client:\n",
    "                with client.write_api(write_options=SYNCHRONOUS) as writer:\n",
    "                    try:\n",
    "                        writer.write(bucket, org=\"globex\", record=[point])\n",
    "                    except InfluxDBError as e:\n",
    "                        print(e)\n",
    "\n",
    "        # Flatten the \"user\" field\n",
    "        user = json_data[\"user\"]\n",
    "        #print(\"User data\")\n",
    "        #print(user)\n",
    "\n",
    "        # Set the remaining fields and tags\n",
    "        for key, value in json_data[\"user\"].items():\n",
    "            if key != \"user\":\n",
    "                if isinstance(value, dict):\n",
    "                    # Handle other nested fields if needed\n",
    "                    pass\n",
    "                else:\n",
    "                    point.field(key, value)\n",
    "                    #print(key,value)\n",
    "\n",
    "        with InfluxDBClient(url, token) as client:\n",
    "            with client.write_api(write_options=SYNCHRONOUS) as writer:\n",
    "                try:\n",
    "                    writer.write(bucket, org=\"globex\", record=[point])\n",
    "                except InfluxDBError as e:\n",
    "                    print(e)\n",
    "\n",
    "        # Set the remaining fields and tags\n",
    "        for key, value in json_data.items():\n",
    "            if key != \"user\" or key != \"data\":\n",
    "                if isinstance(value, dict):\n",
    "                    # Handle other nested fields if needed\n",
    "                    pass\n",
    "                else:\n",
    "                    point.field(key, value)\n",
    "\n",
    "        with InfluxDBClient(url, token) as client:\n",
    "            with client.write_api(write_options=SYNCHRONOUS) as writer:\n",
    "                try:\n",
    "                    writer.write(bucket, org=\"globex\", record=[point])\n",
    "                except InfluxDBError as e:\n",
    "                    print(e)\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Non-JSON message received, skipping...\")\n",
    "    except KeyError:\n",
    "        print(\"Missing fields in JSON message, skipping...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4842a2-113c-4e88-9ad8-a1113e54352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the query to retrieve the data\n",
    "from kafka.consumer import KafkaConsumer\n",
    "from kafka.producer import KafkaProducer\n",
    "from kafka.errors import KafkaError\n",
    "from transformers import pipeline\n",
    "import ssl\n",
    "import json\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from ssl import SSLContext, PROTOCOL_TLSv1\n",
    "from influxdb import InfluxDBClient\n",
    "import influxdb_client\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "from influxdb_client import InfluxDBClient, Point, WriteOptions\n",
    "from dateutil import parser\n",
    "\n",
    "bucket = \"globex-bucket\"\n",
    "org = \"globex\"\n",
    "token = \"2avH4WIAuQagJ_E5Q-SgA50x1K79IT5ruql27hH0bklvYZrrnKeuc3lvlvMx_SSvPwTlVe3chV66IcOUl43EaA==\"\n",
    "# Store the URL of your InfluxDB instance\n",
    "url=\"http://influxdb-influxdb.apps.cluster-kcmwd.kcmwd.sandbox1886.opentlc.com\"\n",
    "\n",
    "client = influxdb_client.InfluxDBClient(\n",
    "   url=url,\n",
    "   token=token,\n",
    "   org=org\n",
    ")\n",
    "\n",
    "query = 'from(bucket: \"globex-bucket\") |> range(start: 0) |> filter(fn: (r) => r._measurement == \"globex-bucket\")'\n",
    "\n",
    "# Run the query\n",
    "query_api = client.query_api()\n",
    "result = query_api.query(query)\n",
    "\n",
    "# Check if any data points are returned\n",
    "if result:\n",
    "    # Iterate over the result and print the data points\n",
    "    for table in result:\n",
    "        for record in table.records:\n",
    "            print(record.values)\n",
    "else:\n",
    "    print(\"No data points found in InfluxDB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932f892d-af29-4933-9f22-7bff9541e6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the list of databases\n",
    "query_api = client.query_api()\n",
    "query = 'import \"influxdata/influxdb/schema\"\\n' \\\n",
    "        'schema.bucket()'\n",
    "print(query)\n",
    "result = query_api.query(org=org, query=query)\n",
    "database_names = [db.name for db in result]\n",
    "print(\"Buckets:\")\n",
    "for db_name in database_names:\n",
    "    print(db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d06698a-81a1-409f-955b-fceb788289d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "database_name = \"globex\"\n",
    "\n",
    "# Create a new database\n",
    "endpoint = f\"{url}/api/v2/orgs/{org}/buckets\"\n",
    "headers = {\"Authorization\": f\"Token {token}\"}\n",
    "data = {\n",
    "    \"name\": database_name,\n",
    "    \"orgID\": org,\n",
    "    \"type\": \"user\",\n",
    "    \"description\": \"Your database description\"\n",
    "}\n",
    "\n",
    "response = requests.post(endpoint, headers=headers, json=data)\n",
    "\n",
    "if response.status_code == 201:\n",
    "    print(f\"Database '{database_name}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to create database. Status code: {response.status_code}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2dea01-618f-4fbf-8b15-48855be23b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
